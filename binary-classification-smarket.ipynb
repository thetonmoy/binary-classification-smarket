{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7434a4ca-f0d9-4b57-a3f5-cb77ddc6af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "923527ac-e112-4985-bb7e-3b4740d15d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Smarket.csv\")\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f6ec72c-ec02-4a5c-963c-db187b4e3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Direction'] = data['Direction'].map({'Up': 1, 'Down': 0})\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ff663-59ea-4965-9830-35eb6ad8a1cb",
   "metadata": {},
   "source": [
    "**Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "527fe768-05fb-4567-a322-3b4991f7c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(len(data) * 0.75)\n",
    "\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_data = data.iloc[:split_index]\n",
    "test_data = data.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7c5ef67-bfcf-42b9-bdf4-f5faffa7d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['Year', 'Direction'], axis=1)\n",
    "y_train = train_data['Direction']\n",
    "\n",
    "X_test = test_data.drop(['Year', 'Direction'], axis=1)\n",
    "y_test = test_data['Direction']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd28fdd-eddd-4bc0-ad45-0efdba727024",
   "metadata": {},
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da416d4e-005b-4827-aa72-2ce6009158ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(df, columns):\n",
    "    normalized_df = df.copy()\n",
    "    for column in columns:\n",
    "        col_min = df[column].min()\n",
    "        col_max = df[column].max()\n",
    "        normalized_df[column] = (df[column] - col_min) / (col_max - col_min)\n",
    "    return normalized_df\n",
    "\n",
    "columns_to_scale = ['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume', 'Today']\n",
    "\n",
    "X_train = min_max_normalization(X_train, columns_to_scale)\n",
    "X_test = min_max_normalization(X_test, columns_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a03cd02d-19c9-4e23-8961-9062264271f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.describe())\n",
    "# print(X_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "954f212f-bf12-4e92-9f46-af23994972d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize weights and bias\n",
    "num_features = X_train.shape[1]\n",
    "weights = np.zeros(num_features)\n",
    "bias = 0\n",
    "learning_rate = 0.02\n",
    "num_epochs = 2500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8baec59-3c4e-43bd-9d04-77040a0a5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4925a9bc-0f3a-403b-a85d-a6964d0f6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "305d8fa7-2792-4ecd-ac20-39e04cda41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931\n",
      "Epoch 100, Loss: 0.6900\n",
      "Epoch 200, Loss: 0.6873\n",
      "Epoch 300, Loss: 0.6845\n",
      "Epoch 400, Loss: 0.6819\n",
      "Epoch 500, Loss: 0.6792\n",
      "Epoch 600, Loss: 0.6766\n",
      "Epoch 700, Loss: 0.6740\n",
      "Epoch 800, Loss: 0.6715\n",
      "Epoch 900, Loss: 0.6690\n",
      "Epoch 1000, Loss: 0.6665\n",
      "Epoch 1100, Loss: 0.6640\n",
      "Epoch 1200, Loss: 0.6616\n",
      "Epoch 1300, Loss: 0.6591\n",
      "Epoch 1400, Loss: 0.6568\n",
      "Epoch 1500, Loss: 0.6544\n",
      "Epoch 1600, Loss: 0.6521\n",
      "Epoch 1700, Loss: 0.6497\n",
      "Epoch 1800, Loss: 0.6475\n",
      "Epoch 1900, Loss: 0.6452\n",
      "Epoch 2000, Loss: 0.6430\n",
      "Epoch 2100, Loss: 0.6408\n",
      "Epoch 2200, Loss: 0.6386\n",
      "Epoch 2300, Loss: 0.6364\n",
      "Epoch 2400, Loss: 0.6343\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Compute predictions\n",
    "    linear_model = np.dot(X_train, weights) + bias\n",
    "    predictions = sigmoid(linear_model)\n",
    "    \n",
    "    # Compute gradients\n",
    "    dw = np.dot(X_train.T, (predictions - y_train)) / len(y_train)\n",
    "    db = np.sum(predictions - y_train) / len(y_train)\n",
    "    \n",
    "    # Update weights and bias\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n",
    "\n",
    "    # Optional: Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        loss = compute_loss(y_train, predictions)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db74520e-d62c-46c3-94b2-531e56aa570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sigmoid(np.dot(X_test, weights) + bias)\n",
    "y_pred_labels = (y_pred >= 0.5).astype(int)  # Convert probabilities to binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c83427e9-57f3-4ecf-94f1-e0792e8bebd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.33%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(y_pred_labels == y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35a3e68a-5550-45d4-8163-f5233e1f0c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6321\n",
      "Epoch 100, Loss: 0.6354\n",
      "Epoch 200, Loss: 0.6383\n",
      "Epoch 300, Loss: 0.6410\n",
      "Epoch 400, Loss: 0.6434\n",
      "Epoch 500, Loss: 0.6455\n",
      "Epoch 600, Loss: 0.6475\n",
      "Epoch 700, Loss: 0.6493\n",
      "Epoch 800, Loss: 0.6509\n",
      "Epoch 900, Loss: 0.6523\n",
      "Epoch 1000, Loss: 0.6536\n",
      "Epoch 1100, Loss: 0.6548\n",
      "Epoch 1200, Loss: 0.6559\n",
      "Epoch 1300, Loss: 0.6568\n",
      "Epoch 1400, Loss: 0.6577\n",
      "Epoch 1500, Loss: 0.6585\n",
      "Epoch 1600, Loss: 0.6592\n",
      "Epoch 1700, Loss: 0.6598\n",
      "Epoch 1800, Loss: 0.6604\n",
      "Epoch 1900, Loss: 0.6609\n",
      "Epoch 2000, Loss: 0.6614\n",
      "Epoch 2100, Loss: 0.6618\n",
      "Epoch 2200, Loss: 0.6622\n",
      "Epoch 2300, Loss: 0.6625\n",
      "Epoch 2400, Loss: 0.6628\n"
     ]
    }
   ],
   "source": [
    "lambda_reg = 0.05  # Regularization strength\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute predictions\n",
    "    linear_model = np.dot(X_train, weights) + bias\n",
    "    predictions = sigmoid(linear_model)\n",
    "    \n",
    "    # Compute gradients with L2 regularization\n",
    "    dw = np.dot(X_train.T, (predictions - y_train)) / len(y_train) + lambda_reg * weights\n",
    "    db = np.sum(predictions - y_train) / len(y_train)\n",
    "    \n",
    "    # Update weights and bias\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n",
    "\n",
    "    # Optional: Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        loss = compute_loss(y_train, predictions)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "621896ee-0f06-425a-a915-fbb83ea6e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sigmoid(np.dot(X_test, weights) + bias)\n",
    "y_pred_labels = (y_pred >= 0.5).astype(int)  # Convert probabilities to binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc6c3cfe-bb22-4180-9eb2-6b0edf356b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.12%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(y_pred_labels == y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
